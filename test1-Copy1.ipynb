{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x64f4ba8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'42,50,270900,270944,267,17,44,24220,76,108,1687,1,0,80,0.0498,0.2415,0.1818,0.0047,0.4706,1,1,2.4265,0.9031,1.6435,0.8182,-0.2913,0.5822,Pastry'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rdd=sc.textFile(\"file:\\Users\\Akshay\\Desktop\\data.csv\")\n",
    "my_rdd.take(4)\n",
    "\n",
    "header= my_rdd.first()\n",
    "my_rdd=my_rdd.filter(lambda x :x!=header)\n",
    "my_rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [42.0,50.0,270900.0,270944.0,267.0,17.0,44.0,24220.0,76.0,108.0,1687.0,1.0,0.0,80.0,0.0498,0.2415,0.1818,0.0047,0.4706,1.0,1.0,2.4265,0.9031,1.6435,0.8182,-0.2913,0.5822]),\n",
       " LabeledPoint(0.0, [645.0,651.0,2538079.0,2538108.0,108.0,10.0,30.0,11397.0,84.0,123.0,1687.0,1.0,0.0,80.0,0.7647,0.3793,0.2069,0.0036,0.6,0.9667,1.0,2.0334,0.7782,1.4624,0.7931,-0.1756,0.2984]),\n",
       " LabeledPoint(0.0, [829.0,835.0,1553913.0,1553931.0,71.0,8.0,19.0,7972.0,99.0,125.0,1623.0,1.0,0.0,100.0,0.971,0.3426,0.3333,0.0037,0.75,0.9474,1.0,1.8513,0.7782,1.2553,0.6667,-0.1228,0.215]),\n",
       " LabeledPoint(0.0, [853.0,860.0,369370.0,369415.0,176.0,13.0,45.0,18996.0,99.0,126.0,1353.0,0.0,1.0,290.0,0.7287,0.4413,0.1556,0.0052,0.5385,1.0,1.0,2.2455,0.8451,1.6532,0.8444,-0.1568,0.5212])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LabeledPoint, LogisticRegressionModel\n",
    "import numpy as np\n",
    "\n",
    "def parse(line):\n",
    "    fields = line.split(\",\")\n",
    "    X_Min = float(fields[0])\n",
    "    X_Max = float(fields[1])\n",
    "    Y_Min = float(fields[2])\n",
    "    Y_Max = float(fields[3])\n",
    "    Pixels_Areas=float(fields[4])\n",
    "    X_Perimeter=float(fields[5])\n",
    "    Y_Perimeter=float(fields[6])\n",
    "    Sum_of_Luminosity=float(fields[7])\n",
    "    Minimum_of_Luminosity=float(fields[8])\n",
    "    Maximum_of_Luminosity=float(fields[9])\n",
    "    Length_of_Conveyer=float(fields[10])\n",
    "    TypeOfSteel_A300=float(fields[11])\n",
    "    TypeOfSteel_A400=float(fields[12])\n",
    "    Steel_Plate_Thickness=float(fields[13])\n",
    "    Edges_Index=float(fields[14])\n",
    "    Empty_Index=float(fields[15])\n",
    "    Square_Index=float(fields[16])\n",
    "    Outside_X_Index=float(fields[17])\n",
    "    Edges_X_Index=float(fields[18])\n",
    "    Edges_Y_Index=float(fields[19])\n",
    "    Outside_Global_Index=float(fields[20])\n",
    "    LogOfAreas=float(fields[21])\n",
    "    Log_X_Index=float(fields[22])\n",
    "    Log_Y_Index=float(fields[23])\n",
    "    Orientation_Index=float(fields[24])\n",
    "    Luminosity_Index=float(fields[25])\n",
    "    SigmoidOfAreas=float(fields[26])\n",
    "\n",
    "\n",
    "    \n",
    "    if fields[27] == 'Pastry':\n",
    "            target = 0\n",
    "    elif fields[27]=='Z_Scratch':\n",
    "            target = 1\n",
    "    elif fields[27]=='K_Scratch':\n",
    "            target = 2\n",
    "    elif fields[27]=='Stains':\n",
    "            target = 3\n",
    "    elif fields[27]=='Bumps':\n",
    "            target = 4\n",
    "    elif fields[27]=='Dirtiness':\n",
    "            target = 5\n",
    "    else:\n",
    "            target = 6\n",
    "    class_var=target\n",
    "    \n",
    "    return LabeledPoint(class_var,(X_Min,X_Max,Y_Min,Y_Max,Pixels_Areas,X_Perimeter,Y_Perimeter,Sum_of_Luminosity,Minimum_of_Luminosity,\\\n",
    "                                    Maximum_of_Luminosity,Length_of_Conveyer,TypeOfSteel_A300,TypeOfSteel_A400,Steel_Plate_Thickness,Edges_Index,\\\n",
    "                                    Empty_Index,Square_Index,Outside_X_Index,Edges_X_Index,Edges_Y_Index,Outside_Global_Index,LogOfAreas,Log_X_Index,\\\n",
    "                                    Log_Y_Index,Orientation_Index,Luminosity_Index,SigmoidOfAreas))\n",
    "\n",
    "#     return LabeledPoint(class_var,(X_Min,X_Max,Y_Min,Y_Max,Pixels_Areas,X_Perimeter,Y_Perimeter))\n",
    "\n",
    "parsedData=my_rdd.map(parse)\n",
    "\n",
    "parsedData.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, test = parsedData.randomSplit([0.7, 0.3],11L)\n",
    "\n",
    "logit_model=LogisticRegressionWithLBFGS.train(training,numClasses=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MultilabelMetrics,MulticlassMetrics\n",
    "predictionAndLabels = test.map(lambda lp: (float(logit_model.predict(lp.features)), lp.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictionAndLabels = test.map(lambda lp: (DoubleType(logit_model.predict(lp.features)), lp.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics=MulticlassMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.813253012048\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy\n",
    "print(\"Accuracy is : %s\"%accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :DenseMatrix([[ 148.,    8.,    0.,    1.,   12.,    5.,   12.],\n",
      "             [   2.,  180.,    1.,    0.,    5.,    1.,    4.],\n",
      "             [   0.,    1.,  199.,    0.,    1.,    0.,    6.],\n",
      "             [   0.,    0.,    0.,  177.,    0.,    1.,    1.],\n",
      "             [  13.,    8.,    0.,    1.,  133.,    5.,   32.],\n",
      "             [   8.,    0.,    0.,    0.,    0.,  164.,   16.],\n",
      "             [  23.,    8.,   12.,    3.,   40.,   18.,   79.]])\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix=metrics.confusionMatrix()\n",
    "print(\"Confusion Matrix :%s\"%confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Logistic Regression model:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "histogram() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8e2498830ec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Learned Logistic Regression model:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictionAndLabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: histogram() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
